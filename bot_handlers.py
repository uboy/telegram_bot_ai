"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –±–æ—Ç–∞
"""
import os
import tempfile
import hashlib
from datetime import datetime, timezone
from typing import Optional
from telegram import Update
from telegram.ext import ContextTypes
from database import Session, User, Message, KnowledgeBase, KnowledgeImportLog
from logging_config import logger
from ai_providers import ai_manager
from rag_system import rag_system
from document_loaders import document_loader_manager
from image_processor import image_processor
from web_search import search_web, format_search_results
from utils import format_text_safe, create_prompt_with_language, detect_language
from urllib.parse import urlparse, parse_qs, unquote


def _normalize_wiki_url_for_display(url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å URL –≤–∏–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å export URL –≤ —á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç)"""
    if not url or not url.startswith(('http://', 'https://')):
        return url
    
    # –ï—Å–ª–∏ —ç—Ç–æ export URL Gitee –≤–∏–∫–∏, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    # –ü—Ä–∏–º–µ—Ä: https://gitee.com/.../wikis/pages/export?type=markdown&doc_id=2921510
    # -> https://gitee.com/.../wikis/Sync&Build/Sync%26Build
    if '/wikis/pages/export' in url:
        try:
            parsed = urlparse(url)
            query_params = parse_qs(parsed.query)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º doc_id –∏–∑ query –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            if 'doc_id' in query_params:
                doc_id = query_params['doc_id'][0]
                # –°—Ç—Ä–æ–∏–º –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π URL –≤–∏–∫–∏
                # –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –¥–æ /wikis
                path_parts = parsed.path.split('/wikis')
                if len(path_parts) >= 2:
                    base_path = path_parts[0] + '/wikis'
                    # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å doc_id
                    # –î–ª—è Gitee –æ–±—ã—á–Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å doc_id –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è URL
                    # –ù–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å –≤–∏–∫–∏
                    return f"{parsed.scheme}://{parsed.netloc}{base_path}"
        except Exception:
            pass
    
    # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω—ã–π URL –≤–∏–∫–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    return url
from templates.buttons import (
    main_menu, admin_menu, settings_menu, ai_providers_menu,
    user_management_menu, knowledge_base_menu, kb_actions_menu,
    document_type_menu, confirm_menu, search_options_menu
)
from config import ADMIN_IDS
from n8n_client import n8n_client

session = Session()


def emit_n8n_import_event(
    kb_id: int,
    action_type: str,
    source_path: str,
    total_chunks: int,
    user_info: Optional[dict] = None,
    extra: Optional[dict] = None,
) -> None:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –æ –∑–∞–≥—Ä—É–∑–∫–µ –∑–Ω–∞–Ω–∏–π –≤ n8n (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)."""
    if not n8n_client.has_webhook():
        return

    kb = rag_system.get_knowledge_base(kb_id)
    payload = {
        "knowledge_base": {
            "id": kb_id,
            "name": getattr(kb, "name", None) if kb else None,
        },
        "action_type": action_type,
        "source_path": source_path,
        "total_chunks": total_chunks,
        "timestamp": datetime.now(timezone.utc).isoformat(),
    }
    if user_info:
        payload["user"] = user_info
    if extra:
        payload["details"] = extra

    ok, message = n8n_client.send_event("knowledge_import", payload)
    if not ok:
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ n8n: %s", message)


async def check_user(update: Update) -> Optional[User]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = str(update.effective_user.id)
    user_id_int = int(update.effective_user.id)
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º
    is_admin = user_id_int in ADMIN_IDS
    
    user = session.query(User).filter_by(telegram_id=user_id).first()
    
    if not user:
        # –ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        user = User(
            telegram_id=user_id,
            username=update.effective_user.username or user_id,
            approved=is_admin,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–¥–æ–±—Ä–∏—Ç—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤
            role='admin' if is_admin else 'user'
        )
        session.add(user)
        session.commit()
        
        if is_admin:
            # –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä - —Å—Ä–∞–∑—É –æ–¥–æ–±—Ä–µ–Ω
            if update.message:
                await update.message.reply_text("‚úÖ –í—ã –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä. –î–æ—Å—Ç—É–ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")
            return user
        else:
            # –û–±—ã—á–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∞–º
            for admin in ADMIN_IDS:
                try:
                    await update.get_bot().send_message(
                        chat_id=admin,
                        text=f"–ù–æ–≤–∞—è –∑–∞—è–≤–∫–∞: @{user.username} (ID: {user_id})",
                        reply_markup=approve_menu(user_id)
                    )
                except:
                    pass
            
            if update.message:
                await update.message.reply_text("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é. –û–∂–∏–¥–∞–π—Ç–µ –æ–¥–æ–±—Ä–µ–Ω–∏—è.")
            return None
    
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    if is_admin:
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Å–ø–∏—Å–∫–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–¥–æ–±—Ä–∏—Ç—å –∏ —Å–¥–µ–ª–∞—Ç—å –∞–¥–º–∏–Ω–æ–º
        if not user.approved or user.role != 'admin':
            user.approved = True
            user.role = 'admin'
            session.commit()
        return user
    
    if not user.approved:
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –æ–¥–æ–±—Ä–µ–Ω - –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
        if update.message:
            await update.message.reply_text("‚è≥ –í–∞—à–∞ –∑–∞—è–≤–∫–∞ –µ—â–µ –Ω–µ –æ–¥–æ–±—Ä–µ–Ω–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
        return None
    
    return user


from templates.buttons import approve_menu


async def handle_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = await check_user(update)
    if not user:
        return
    
    text = "üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –±–æ—Ç–∞-–ø–æ–º–æ—â–Ω–∏–∫–∞!\n\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:"
    menu = main_menu(is_admin=(user.role == 'admin'))
    await update.message.reply_text(text, reply_markup=menu)
    logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s (%s) –∑–∞–ø—É—Å—Ç–∏–ª /start", user.username, user.telegram_id)


async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user = await check_user(update)
    if not user:
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –æ–¥–æ–±—Ä–µ–Ω –∏–ª–∏ –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω
        # check_user —É–∂–µ –æ—Ç–ø—Ä–∞–≤–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –æ–∂–∏–¥–∞–µ—Ç—Å—è –ª–∏ –≤–≤–æ–¥ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    chat_id = str(update.effective_chat.id)
    state = context.user_data.get('state')
    text_input = update.message.text.strip() if update.message and update.message.text else ""

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ "–∫–Ω–æ–ø–æ–∫" –æ–±—ã—á–Ω–æ–π –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã (ReplyKeyboardMarkup) –≤—Å–µ–≥–¥–∞ –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    if text_input == "üîç –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π":
        context.user_data['state'] = 'waiting_query'
        await update.message.reply_text("üîç –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π:")
        logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –≤—ã–±—Ä–∞–ª —Ä–µ–∂–∏–º: –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π", user.telegram_id)
        return
    if text_input == "üåê –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ":
        context.user_data['state'] = 'waiting_web_query'
        await update.message.reply_text("üåê –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ:")
        logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –≤—ã–±—Ä–∞–ª —Ä–µ–∂–∏–º: –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ", user.telegram_id)
        return
    if text_input == "ü§ñ –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ò–ò":
        context.user_data['state'] = 'waiting_ai_query'
        await update.message.reply_text("ü§ñ –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ò–ò:")
        logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –≤—ã–±—Ä–∞–ª —Ä–µ–∂–∏–º: –ø—Ä—è–º–æ–π –≤–æ–ø—Ä–æ—Å –ò–ò", user.telegram_id)
        return
    if text_input == "üñºÔ∏è –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ":
        await update.message.reply_text("üñºÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        logger.info("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å %s –≤—ã–±—Ä–∞–ª —Ä–µ–∂–∏–º: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", user.telegram_id)
        return
    if text_input == "üë®‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å" and user.role == 'admin':
        await update.message.reply_text("üë®‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å:", reply_markup=admin_menu())
        logger.info("–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä %s –æ—Ç–∫—Ä—ã–ª –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å", user.telegram_id)
        return
    
    if state == 'waiting_query':
        # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        query = update.message.text
        # –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ RAG –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        try:
            from config import RAG_TOP_K
            top_k_search = RAG_TOP_K
        except ImportError:
            top_k_search = 10
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º top_k –¥–ª—è –ª—É—á—à–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results = rag_system.search(query, top_k=top_k_search)
        logger.info("–ü–æ–∏—Å–∫ –≤ –ë–ó: user=%s, query=%r, –Ω–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤=%s", user.telegram_id, query, len(results))
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ò–ò –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
        if results:
            # –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ RAG –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            try:
                from config import RAG_TOP_K, RAG_CONTEXT_LENGTH, RAG_ENABLE_CITATIONS
                top_k_for_context = RAG_TOP_K
                context_length = RAG_CONTEXT_LENGTH
                enable_citations = RAG_ENABLE_CITATIONS
            except ImportError:
                top_k_for_context = 8
                context_length = 1200
                enable_citations = True
            
            # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ source_id —Ç–µ–≥–∞–º–∏ –¥–ª—è citations
            context_parts = []
            sources = []
            for idx, r in enumerate(results[:top_k_for_context], start=1):
                source_type = r.get('source_type') or 'unknown'
                source_path = r.get('source_path') or ''
                meta = r.get('metadata') or {}
                title = meta.get('title') or source_path or '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                doc_version = meta.get('doc_version')
                language = meta.get('language')
                updated_at = meta.get('source_updated_at')

                # –§–æ—Ä–º–∏—Ä—É–µ–º source_id –¥–ª—è citation (–∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–ª–∏ –ø—É—Ç—å)
                if source_path and '.keep' not in source_path.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è source_id
                    if '::' in source_path:
                        # –î–ª—è –∞—Ä—Ö–∏–≤–æ–≤: –±–µ—Ä–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ö–∏–≤–∞
                        source_id = source_path.split('::')[-1]
                    elif '/' in source_path:
                        # –î–ª—è URL –∏–ª–∏ –ø—É—Ç–µ–π: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
                        source_id = source_path.split('/')[-1]
                    else:
                        source_id = source_path
                    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º–æ–≥–æ citation
                    source_id = source_id.rsplit('.', 1)[0] if '.' in source_id else source_id
                else:
                    source_id = title.replace(' ', '_').lower()[:50]  # Fallback –Ω–∞ title

                content_preview = r['content'][:context_length]
                if len(r['content']) > context_length:
                    content_preview += "..."
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ç–µ–≥–æ–º <source_id> –¥–ª—è inline citations
                if enable_citations:
                    context_parts.append(
                        f"<source_id>{source_id}</source_id>\n{content_preview}"
                    )
                else:
                    header = f"=== –ò—Å—Ç–æ—á–Ω–∏–∫ {idx}: {title} ==="
                    context_parts.append(
                        f"{header}\n{content_preview}"
                    )

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –¥–ª—è —Å–ø–∏—Å–∫–∞ –≤ –∫–æ–Ω—Ü–µ (–≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ)
                from html import escape
                if source_path and '.keep' not in source_path.lower() and source_path.startswith(('http://', 'https://')):
                    # –î–ª—è URL —Å–æ–∑–¥–∞–µ–º HTML —Å—Å—ã–ª–∫—É
                    display_path = _normalize_wiki_url_for_display(source_path)
                    url_for_link = source_path if source_path else display_path
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –ø—É—Ç–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    if '/' in url_for_link:
                        parts = [p for p in url_for_link.split('/') if p]
                        if parts:
                            title_from_url = parts[-1]
                        else:
                            title_from_url = url_for_link
                    else:
                        title_from_url = url_for_link
                    
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º URL –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                    title_from_url = unquote(title_from_url)
                    
                    # –ï—Å–ª–∏ title –∏–∑ URL –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º title –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    if not title_from_url or len(title_from_url) < 2:
                        parts = [p for p in url_for_link.split('/') if p]
                        if len(parts) > 1:
                            title_from_url = unquote(parts[-2])
                        else:
                            title_from_url = title
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º title –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω –ª—É—á—à–µ
                    display_title = title if title and title != '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è' else title_from_url
                    
                    title_escaped = escape(display_title)
                    url_escaped = escape(url_for_link)
                    source_info = f"{idx}. <a href=\"{url_escaped}\">{title_escaped}</a>"
                else:
                    # –î–ª—è –Ω–µ-URL –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
                    title_escaped = escape(title)
                    if source_path and '.keep' not in source_path.lower():
                        if '::' in source_path:
                            file_name = source_path.split('::')[-1]
                        elif '/' in source_path:
                            file_name = source_path.split('/')[-1]
                        else:
                            file_name = source_path
                        file_name_escaped = escape(file_name)
                        source_info = f"{idx}. <b>{title_escaped}</b> (<code>{file_name_escaped}</code>)"
                    else:
                        source_info = f"{idx}. <b>{title_escaped}</b>"
                sources.append(source_info)
            
            context_text = "\n\n".join(context_parts)
            prompt = create_prompt_with_language(
                query,
                context_text,
                task="answer",
                enable_citations=enable_citations,
            )
            model = user.preferred_model if user.preferred_model else None
            ai_answer = ai_manager.query(
                prompt,
                provider_name=user.preferred_provider,
                model=model,
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å HTML –¥–ª—è –ª—É—á—à–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            from utils import format_markdown_to_html
            ai_answer_html = format_markdown_to_html(ai_answer)
            # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —É–∂–µ –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–∞
            sources_html = "\n".join([f"‚Ä¢ {s}" for s in sources])
            answer_html = f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{ai_answer_html}\n\nüìé <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:</b>\n{sources_html}"
        else:
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç–∏—Ç—å —á–µ—Ä–µ–∑ –ò–ò
            prompt = create_prompt_with_language(query, None, task="answer")
            model = user.preferred_model if user.preferred_model else None
            ai_answer = ai_manager.query(
                prompt, provider_name=user.preferred_provider, model=model
            )
            from utils import format_markdown_to_html
            from html import escape
            ai_answer_html = format_markdown_to_html(ai_answer)
            answer_html = f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{ai_answer_html}\n\n<i>(–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏—è—Ö)</i>"
        
        menu = main_menu(is_admin=(user.role == 'admin'))
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º HTML –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            await update.message.reply_text(answer_html, reply_markup=menu, parse_mode='HTML')
        except Exception as e:
            # –ï—Å–ª–∏ HTML –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.warning("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è HTML, –æ—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: %s", e)
            answer_plain = format_text_safe(answer_html)
            await update.message.reply_text(answer_plain, reply_markup=menu, parse_mode=None)
        context.user_data['state'] = None
        
    elif state == 'waiting_web_query':
        # –ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        query = update.message.text
        await update.message.reply_text("üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ...")
        
        results = search_web(query, max_results=5)
        logger.info("–ü–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ: user=%s, query=%r, —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤=%s", user.telegram_id, query, len(results))
        
        if results:
            # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            search_context = "\n\n".join([
                f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i+1}: {r.get('title', '')}\n{r.get('snippet', '')[:300]}"
                for i, r in enumerate(results[:3])
            ])
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ò–ò –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            prompt = create_prompt_with_language(query, search_context, task="search_summary")
            model = user.preferred_model if user.preferred_model else None
            ai_answer = ai_manager.query(prompt, provider_name=user.preferred_provider, model=model)
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —Å HTML
            from utils import format_markdown_to_html
            ai_answer_html = format_markdown_to_html(ai_answer)
            
            # –î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫–∏ –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ
            sources_html_parts = []
            from html import escape
            for i, result in enumerate(results[:3], 1):
                url = result.get('url', '')
                title = result.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                title_escaped = escape(title)
                if url:
                    sources_html_parts.append(f"‚Ä¢ {i}. <a href=\"{url}\">{title_escaped}</a>")
                else:
                    sources_html_parts.append(f"‚Ä¢ {i}. <b>{title_escaped}</b>")
            
            sources_html = "\n".join(sources_html_parts)
            answer_html = f"üåê <b>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:</b>\n\n{ai_answer_html}\n\nüìé <b>–ò—Å—Ç–æ—á–Ω–∏–∫–∏:</b>\n{sources_html}"
        else:
            answer_html = "‚ùå <b>–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ.</b>\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å."
        
        menu = main_menu(is_admin=(user.role == 'admin'))
        try:
            await update.message.reply_text(answer_html, reply_markup=menu, parse_mode='HTML')
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è HTML, –æ—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: %s", e)
            answer_plain = format_text_safe(answer_html)
            await update.message.reply_text(answer_plain, reply_markup=menu, parse_mode=None)
        context.user_data['state'] = None
        
    elif state == 'waiting_ai_query':
        # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ –ò–ò
        query = update.message.text
        prompt = create_prompt_with_language(query, None, task="answer")
        model = user.preferred_model if user.preferred_model else None
        ai_answer = ai_manager.query(prompt, provider_name=user.preferred_provider, model=model)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å HTML –¥–ª—è –ª—É—á—à–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        from utils import format_markdown_to_html
        ai_answer_html = format_markdown_to_html(ai_answer)
        answer_html = f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{ai_answer_html}"
        
        menu = main_menu(is_admin=(user.role == 'admin'))
        try:
            await update.message.reply_text(answer_html, reply_markup=menu, parse_mode='HTML')
        except Exception as e:
            logger.warning("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è HTML, –æ—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: %s", e)
            answer_plain = format_text_safe(f"ü§ñ –û—Ç–≤–µ—Ç:\n\n{ai_answer}")
            await update.message.reply_text(answer_plain, reply_markup=menu, parse_mode=None)
        context.user_data['state'] = None
        
    elif state == 'waiting_url':
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã
        url = update.message.text
        kb_id = context.user_data.get('kb_id')
        if kb_id:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–π –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –ë–ó: kb_id=%s, url=%s, user=%s", kb_id, url, user.telegram_id)
            await load_web_page(update, context, url, kb_id)
        context.user_data['state'] = None
    
    elif state == 'waiting_wiki_root':
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π —Å–±–æ—Ä wiki-—Ä–∞–∑–¥–µ–ª–∞ —Å–∞–π—Ç–∞
        from wiki_scraper import crawl_wiki_to_kb_async

        wiki_url = (update.message.text or "").strip()
        kb_id = context.user_data.get('kb_id_for_wiki')

        if not kb_id:
            await update.message.reply_text(
                "–ù–µ –≤—ã–±—Ä–∞–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–∫–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –ë–ó –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏.",
                reply_markup=admin_menu(),
            )
            context.user_data['state'] = None
            return

        await update.message.reply_text(
            "üöÄ –ó–∞–ø—É—Å–∫–∞—é —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –≤–∏–∫–∏.\n"
            "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–æ–≤ —Ä–∞–∑–¥–µ–ª–∞.",
        )
        logger.info("–°—Ç–∞—Ä—Ç —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∏–∫–∏ –∏–∑ Telegram: kb_id=%s, url=%s, user=%s", kb_id, wiki_url, user.telegram_id)

        try:
            stats = await crawl_wiki_to_kb_async(wiki_url, kb_id, max_pages=500)
            deleted = stats.get("deleted_chunks", 0)
            pages = stats.get("pages_processed", 0)
            added = stats.get("chunks_added", 0)
            wiki_root = stats.get("wiki_root", wiki_url)

            # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫
            tg_id = str(update.effective_user.id) if update.effective_user else ""
            db_user = session.query(User).filter_by(telegram_id=tg_id).first() if tg_id else None
            username = db_user.username if db_user else tg_id
            user_info = {"telegram_id": tg_id, "username": username}
            log = KnowledgeImportLog(
                knowledge_base_id=kb_id,
                user_telegram_id=tg_id,
                username=username,
                action_type="wiki",
                source_path=wiki_root,
                total_chunks=added,
            )
            session.add(log)
            session.commit()

            emit_n8n_import_event(
                kb_id=kb_id,
                action_type="wiki",
                source_path=wiki_root,
                total_chunks=added,
                user_info=user_info,
                extra={
                    "deleted_chunks": deleted,
                    "pages_processed": pages,
                    "wiki_root": wiki_root,
                    "original_url": wiki_url,
                },
            )

            text = (
                "‚úÖ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n\n"
                f"–ò—Å—Ö–æ–¥–Ω—ã–π URL: {wiki_url}\n"
                f"–ö–æ—Ä–Ω–µ–≤–æ–π wiki-URL: {wiki_root}\n"
                f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {deleted}\n"
                f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {pages}\n"
                f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {added}"
            )
            
            # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –º–∞–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü (<= 1), –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –¥–æ–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ git –∏–ª–∏ zip
            if pages <= 1:
                from templates.buttons import InlineKeyboardButton, InlineKeyboardMarkup
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º MD5 —Ö–µ—à –¥–ª—è URL, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ callback_data (64 –±–∞–π—Ç–∞)
                import hashlib
                wiki_url_hash = hashlib.md5(wiki_url.encode('utf-8')).hexdigest()[:8]
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π URL –≤ context –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                if 'wiki_urls' not in context.user_data:
                    context.user_data['wiki_urls'] = {}
                context.user_data['wiki_urls'][wiki_url_hash] = wiki_url
                buttons = [
                    [InlineKeyboardButton(
                        "üîó –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–∫–∏ –∏–∑ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è",
                        callback_data=f"wiki_git_load:{kb_id}:{wiki_url_hash}"
                    )],
                    [InlineKeyboardButton(
                        "üì¶ –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–∫–∏ –∏–∑ ZIP –∞—Ä—Ö–∏–≤–∞",
                        callback_data=f"wiki_zip_load:{kb_id}:{wiki_url_hash}"
                    )],
                    [InlineKeyboardButton("üîô –ö –∞–¥–º–∏–Ω-–º–µ–Ω—é", callback_data="admin_menu")]
                ]
                text += (
                    "\n\n‚ö†Ô∏è –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–∞–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü. "
                    "–í–∏–∫–∏ Gitee –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é:\n"
                    "‚Ä¢ –ò–∑ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)\n"
                    "‚Ä¢ –ò–∑ ZIP –∞—Ä—Ö–∏–≤–∞ (–µ—Å–ª–∏ –≤—ã —Å–∫–∞—á–∞–ª–∏ –∞—Ä—Ö–∏–≤ –æ—Ç–¥–µ–ª—å–Ω–æ)"
                )
                await update.message.reply_text(text, reply_markup=InlineKeyboardMarkup(buttons))
            else:
                await update.message.reply_text(text, reply_markup=admin_menu())
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤–∏–∫–∏: %s", e)
            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤–∏–∫–∏: {str(e)}",
                reply_markup=admin_menu(),
            )

        context.user_data['state'] = None
        context.user_data.pop('kb_id_for_wiki', None)
        
    elif state == 'waiting_kb_name':
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
        kb_name = update.message.text
        kb = rag_system.add_knowledge_base(kb_name)
        await update.message.reply_text(f"‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π '{kb_name}' —Å–æ–∑–¥–∞–Ω–∞!", reply_markup=admin_menu())
        context.user_data['state'] = None
        
    elif state == 'waiting_user_delete':
        # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user.role != 'admin':
            await update.message.reply_text("–¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç —É–¥–∞–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.")
            context.user_data['state'] = None
            return
        
        try:
            target_id = update.message.text.strip()
            target_user = session.query(User).filter_by(telegram_id=target_id).first()
            if target_user:
                username = target_user.username
                session.delete(target_user)
                session.commit()
                await update.message.reply_text(f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å @{username} —É–¥–∞–ª–µ–Ω!", reply_markup=admin_menu())
            else:
                await update.message.reply_text("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω.", reply_markup=admin_menu())
        except Exception as e:
            await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", reply_markup=admin_menu())
        context.user_data['state'] = None
        
    else:
        # –õ—é–±–æ–π –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—á–∏—Ç–∞–µ–º –∑–∞–ø—Ä–æ—Å–æ–º –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        query = update.message.text

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ)
        session.add(Message(
            chat_id=chat_id,
            user=update.effective_user.username or str(update.effective_user.id),
            text=query,
        ))
        session.commit()
        
        # –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ RAG –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        try:
            from config import RAG_TOP_K, RAG_MAX_CANDIDATES
            top_k_search = RAG_TOP_K
            max_candidates = RAG_MAX_CANDIDATES
        except ImportError:
            top_k_search = 10
            max_candidates = 100
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
        # Reranker –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ª—É—á—à–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        search_top_k = min(top_k_search * 2, max_candidates)
        results = rag_system.search(query, top_k=search_top_k)
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ top_k –ª—É—á—à–∏—Ö –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (reranker —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª)
        results = results[:top_k_search]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã –∏ —Ñ–∞–π–ª—ã .keep
        filtered_results = []
        for r in results:
            content = r.get('content', '').strip()
            source_path = r.get('source_path', '')
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã –∏ —Ñ–∞–π–ª—ã .keep
            if not content or len(content) < 10:
                continue
            if '.keep' in source_path.lower() or source_path.endswith('/.keep'):
                continue
            filtered_results.append(r)
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º –±—ã–ª–∏ –ª–∏ –≤–æ–æ–±—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not filtered_results:
            # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞/—Ç–µ–º—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
            similar_suggestions = []
            if results:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–º
                for r in results[:5]:
                    source_path = r.get('source_path', '')
                    meta = r.get('metadata') or {}
                    title = meta.get('title') or source_path or '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                    if source_path and '.keep' not in source_path.lower():
                        similar_suggestions.append({
                            'title': title,
                            'source_path': source_path
                        })
            
            if similar_suggestions:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–º
                suggestions_text = "–í–æ–∑–º–æ–∂–Ω–æ, –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Ç–µ–º—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n\n"
                for i, sug in enumerate(similar_suggestions[:5], 1):
                    display_url = _normalize_wiki_url_for_display(sug['source_path']) if sug['source_path'] else ''
                    from html import escape
                    title_escaped = escape(sug['title'])
                    if display_url and display_url.startswith(('http://', 'https://')):
                        suggestions_text += f"‚Ä¢ {i}. <a href=\"{display_url}\">{title_escaped}</a>\n"
                    else:
                        suggestions_text += f"‚Ä¢ {i}. <b>{title_escaped}</b>\n"
                
                answer = f"‚ùå <b>–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.</b>\n\n{suggestions_text}"
            else:
                answer = "‚ùå <b>–í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.</b>\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."
            
            menu = main_menu(is_admin=(user.role == 'admin'))
            try:
                await update.message.reply_text(answer, reply_markup=menu, parse_mode='HTML')
            except Exception as e:
                logger.warning("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è HTML, –æ—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: %s", e)
                answer_plain = format_text_safe(answer)
                await update.message.reply_text(answer_plain, reply_markup=menu, parse_mode=None)
            return
        
        if filtered_results:
            # –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ RAG –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
            try:
                from config import RAG_TOP_K, RAG_CONTEXT_LENGTH, RAG_ENABLE_CITATIONS
                top_k_for_context = RAG_TOP_K
                context_length = RAG_CONTEXT_LENGTH
                enable_citations = RAG_ENABLE_CITATIONS
            except ImportError:
                top_k_for_context = 8
                context_length = 1200
                enable_citations = True
            
            context_parts = []
            sources = []
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ top_k –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–µ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            for idx, r in enumerate(filtered_results[:top_k_for_context], start=1):
                source_type = r.get('source_type') or 'unknown'
                source_path = r.get('source_path') or ''
                meta = r.get('metadata') or {}
                title = meta.get('title') or source_path or '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'
                doc_version = meta.get('doc_version')
                language = meta.get('language')
                updated_at = meta.get('source_updated_at')
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º source_id –¥–ª—è citation (–∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏–ª–∏ –ø—É—Ç—å)
                if source_path and '.keep' not in source_path.lower():
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è source_id
                    if '::' in source_path:
                        # –î–ª—è –∞—Ä—Ö–∏–≤–æ–≤: –±–µ—Ä–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ö–∏–≤–∞
                        source_id = source_path.split('::')[-1]
                    elif '/' in source_path:
                        # –î–ª—è URL –∏–ª–∏ –ø—É—Ç–µ–π: –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
                        source_id = source_path.split('/')[-1]
                    else:
                        source_id = source_path
                    # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º–æ–≥–æ citation
                    source_id = source_id.rsplit('.', 1)[0] if '.' in source_id else source_id
                else:
                    source_id = title.replace(' ', '_').lower()[:50]  # Fallback –Ω–∞ title
                
                content_preview = r['content'][:context_length]
                if len(r['content']) > context_length:
                    content_preview += "..."

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ç–µ–≥–æ–º <source_id> –¥–ª—è inline citations
                if enable_citations:
                    context_parts.append(
                        f"<source_id>{source_id}</source_id>\n{content_preview}"
                    )
                else:
                    header = f"=== –ò—Å—Ç–æ—á–Ω–∏–∫ {idx}: {title} ==="
                    context_parts.append(
                        f"{header}\n{content_preview}"
                    )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è HTML —Å–ø–∏—Å–∫–∞
                sources.append({
                    'title': title,
                    'source_path': source_path,
                    'index': idx
                })
            
            context_text = "\n\n".join(context_parts)
            prompt = create_prompt_with_language(
                query,
                context_text,
                task="answer",
                enable_citations=enable_citations,
            )
            model = user.preferred_model if user.preferred_model else None
            ai_answer = ai_manager.query(
                prompt,
                provider_name=user.preferred_provider,
                model=model,
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å HTML –¥–ª—è –ª—É—á—à–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            from utils import format_markdown_to_html
            ai_answer_html = format_markdown_to_html(ai_answer)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º HTML —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å —Å—Å—ã–ª–∫–∞–º–∏
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º URL –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            seen_urls = set()
            sources_html_parts = []
            source_counter = 1
            
            for source_data in sources:
                idx = source_data['index']
                title = source_data['title']
                source_path = source_data['source_path']
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL –¥–ª—è –≤–∏–∫–∏
                display_url = _normalize_wiki_url_for_display(source_path) if source_path else source_path
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π URL –∫–∞–∫ –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
                url_key = display_url if display_url else source_path
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                if url_key in seen_urls:
                    continue
                seen_urls.add(url_key)
                
                # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º title –¥–ª—è HTML
                from html import escape
                title_escaped = escape(title)
                
                if display_url and display_url.startswith(('http://', 'https://')):
                    # –°–æ–∑–¥–∞–µ–º HTML —Å—Å—ã–ª–∫—É —Å –ø–æ–ª–Ω—ã–º URL –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                    sources_html_parts.append(f"‚Ä¢ {source_counter}. <a href=\"{display_url}\">{title_escaped}</a>")
                else:
                    # –ë–µ–∑ —Å—Å—ã–ª–∫–∏ (—Ñ–∞–π–ª) - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                    if source_path:
                        if '::' in source_path:
                            file_name = source_path.split('::')[-1]
                        elif '/' in source_path:
                            file_name = source_path.split('/')[-1]
                        else:
                            file_name = source_path
                        file_name_escaped = escape(file_name)
                        sources_html_parts.append(f"‚Ä¢ {source_counter}. <b>{title_escaped}</b> (<code>{file_name_escaped}</code>)")
                    else:
                        sources_html_parts.append(f"‚Ä¢ {source_counter}. <b>{title_escaped}</b>")
                
                source_counter += 1
            
            sources_html = "\n".join(sources_html_parts)
            answer_html = f"ü§ñ <b>–û—Ç–≤–µ—Ç:</b>\n\n{ai_answer_html}\n\nüìé <b>–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:</b>\n{sources_html}"
            answer = answer_html
        # –≠—Ç–æ—Ç –±–ª–æ–∫ –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω, —Ç–∞–∫ –∫–∞–∫ –º—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã—à–µ

        menu = main_menu(is_admin=(user.role == 'admin'))
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º HTML –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        try:
            await update.message.reply_text(answer, reply_markup=menu, parse_mode='HTML')
        except Exception as e:
            # –ï—Å–ª–∏ HTML –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.warning("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è HTML, –æ—Ç–ø—Ä–∞–≤–ª—è—é –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: %s", e)
            answer_plain = format_text_safe(answer)
            await update.message.reply_text(answer_plain, reply_markup=menu, parse_mode=None)


async def load_document_to_kb(query_or_update, context, document_info, kb_id):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    from telegram import Update
    is_update = isinstance(query_or_update, Update)
    temp_path = None
    
    try:
        if is_update:
            bot = query_or_update.get_bot()
            file = await bot.get_file(document_info['file_id'])
            message = query_or_update.message
        else:
            bot = query_or_update.message.bot if hasattr(query_or_update, 'message') else context.bot
            file = await bot.get_file(document_info['file_id'])
            message = None
        
        temp_path = os.path.join(tempfile.gettempdir(), f"{document_info['file_id']}.{document_info['file_type']}")
        await file.download_to_drive(temp_path)
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∂—É—Ä–Ω–∞–ª–∞ –∑–∞–≥—Ä—É–∑–æ–∫
        try:
            if is_update and query_or_update.effective_user:
                tg_id = str(query_or_update.effective_user.id)
            else:
                tg_id = str(query_or_update.from_user.id) if hasattr(query_or_update, "from_user") else ""
        except Exception:
            tg_id = ""
        db_user = session.query(User).filter_by(telegram_id=tg_id).first() if tg_id else None
        username = db_user.username if db_user else tg_id
        user_info = {"telegram_id": tg_id, "username": username}

        file_type = (document_info['file_type'] or '').lower()

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ (zip)
        per_file_stats = []
        total_chunks = 0

        if file_type in ("zip",):
            import zipfile

            with zipfile.ZipFile(temp_path, 'r') as zf:
                for name in zf.namelist():
                    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∫–∞—Ç–∞–ª–æ–≥–∏
                    if name.endswith('/'):
                        continue
                    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–π–ª—ã .keep –∏ –¥—Ä—É–≥–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã
                    if '.keep' in name.lower() or name.endswith('.keep'):
                        continue
                    inner_ext = os.path.splitext(name)[1].lstrip('.').lower()
                    # –ò–∑–≤–ª–µ—á—å –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    with zf.open(name) as src, tempfile.NamedTemporaryFile(delete=False, suffix=f".{inner_ext}") as dst:
                        data = src.read()
                        dst.write(data)
                        inner_path = dst.name
                    # –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–µ—Ä—Å–∏–∏
                    doc_hash = hashlib.sha256(data).hexdigest()
                    # –í –∫–∞—á–µ—Å—Ç–≤–µ source_path –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤–Ω—É—Ç—Ä–∏ –∞—Ä—Ö–∏–≤–∞,
                    # —á—Ç–æ–±—ã –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –∫–∞–∫ —Ä–µ–∞–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç, –∞ –Ω–µ –∞—Ä—Ö–∏–≤.
                    source_path = name

                    # –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)
                    rag_system.delete_chunks_by_source_exact(
                        knowledge_base_id=kb_id,
                        source_type=inner_ext or 'unknown',
                        source_path=source_path,
                    )
                    try:
                        chunks = document_loader_manager.load_document(inner_path, inner_ext or None)
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —á–∞–Ω–∫–∏ (–º–µ–Ω–µ–µ 10 —Å–∏–º–≤–æ–ª–æ–≤)
                        chunks = [chunk for chunk in chunks if chunk.get('content', '').strip() and len(chunk.get('content', '').strip()) > 10]
                    except Exception:
                        chunks = []
                    added = 0
                    # –í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ ‚Äî –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ç–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                    existing_logs = session.query(KnowledgeImportLog).filter_by(
                        knowledge_base_id=kb_id,
                        source_path=source_path,
                    ).count()
                    doc_version = existing_logs + 1
                    source_updated_at = datetime.now(timezone.utc).isoformat()

                    for chunk in chunks:
                        content = chunk.get('content', '')
                        base_meta = dict(chunk.get('metadata') or {})
                        base_meta.setdefault('title', chunk.get('title') or name)
                        base_meta['language'] = detect_language(content) if content else 'ru'
                        base_meta['doc_hash'] = doc_hash
                        base_meta['doc_version'] = doc_version
                        base_meta['source_updated_at'] = source_updated_at

                        rag_system.add_chunk(
                            knowledge_base_id=kb_id,
                            content=content,
                            source_type=inner_ext or 'unknown',
                            source_path=source_path,
                            metadata=base_meta,
                        )
                        added += 1
                    total_chunks += added
                    per_file_stats.append((name, added))
                    # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
                    log = KnowledgeImportLog(
                        knowledge_base_id=kb_id,
                        user_telegram_id=tg_id,
                        username=username,
                        action_type="archive",
                        source_path=source_path,
                        total_chunks=added,
                    )
                    session.add(log)
                    session.commit()
                    emit_n8n_import_event(
                        kb_id=kb_id,
                        action_type="archive",
                        source_path=source_path,
                        total_chunks=added,
                        user_info=user_info,
                        extra={
                            "archive_name": document_info.get('file_name'),
                            "inner_file": name,
                            "doc_hash": doc_hash,
                            "doc_version": doc_version,
                            "source_updated_at": source_updated_at,
                        },
                    )
                    try:
                        os.remove(inner_path)
                    except Exception:
                        pass

            if per_file_stats:
                # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≤—ã–≤–æ–¥, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç Telegram (4096 —Å–∏–º–≤–æ–ª–æ–≤)
                MAX_MESSAGE_LENGTH = 3500  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å
                MAX_FILES_TO_SHOW = 50  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –º–∞–∫—Å–∏–º—É–º 50 —Ñ–∞–π–ª–æ–≤
                
                lines = ["‚úÖ –ê—Ä—Ö–∏–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π:"]
                total_files = len(per_file_stats)
                total_chunks_all = sum(added for _, added in per_file_stats)
                
                # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–µ—Ä–≤—ã–º —Ñ–∞–π–ª–∞–º
                shown_count = 0
                for name, added in per_file_stats[:MAX_FILES_TO_SHOW]:
                    line = f"- {name}: —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ {added}"
                    if len("\n".join(lines) + "\n" + line) > MAX_MESSAGE_LENGTH:
                        break
                    lines.append(line)
                    shown_count += 1
                
                # –î–æ–±–∞–≤–∏—Ç—å –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                if total_files > shown_count:
                    lines.append(f"\n... –∏ –µ—â–µ {total_files - shown_count} —Ñ–∞–π–ª–æ–≤")
                
                lines.append(f"\nüìä –ò—Ç–æ–≥–æ: {total_files} —Ñ–∞–π–ª–æ–≤, {total_chunks_all} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                
                response_text = "\n".join(lines)
                
                # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –µ—â–µ –±–æ–ª—å—à–µ
                if len(response_text) > MAX_MESSAGE_LENGTH:
                    response_text = (
                        f"‚úÖ –ê—Ä—Ö–∏–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!\n\n"
                        f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_files}\n"
                        f"üìù –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {total_chunks_all}\n\n"
                        f"(–ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {shown_count} —Ñ–∞–π–ª–æ–≤ –∏–∑ {total_files})"
                    )
            else:
                response_text = "‚ö†Ô∏è –ê—Ä—Ö–∏–≤ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏."
        else:
            # –û–±—ã—á–Ω—ã–π –æ–¥–∏–Ω–æ—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            with open(temp_path, 'rb') as f:
                data = f.read()
            doc_hash = hashlib.sha256(data).hexdigest()
            source_path = document_info['file_name'] or ''

            # –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
            rag_system.delete_chunks_by_source_exact(
                knowledge_base_id=kb_id,
                source_type=file_type or 'unknown',
                source_path=source_path,
            )

            chunks = document_loader_manager.load_document(temp_path, document_info['file_type'])
            
            # –í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            existing_logs = session.query(KnowledgeImportLog).filter_by(
                knowledge_base_id=kb_id,
                source_path=source_path,
            ).count()
            doc_version = existing_logs + 1
            source_updated_at = datetime.now(timezone.utc).isoformat()

            added = 0
            for chunk in chunks:
                content = chunk['content']
                base_meta = dict(chunk.get('metadata') or {})
                base_meta.setdefault('title', chunk.get('title') or source_path)
                base_meta['language'] = detect_language(content) if content else 'ru'
                base_meta['doc_hash'] = doc_hash
                base_meta['doc_version'] = doc_version
                base_meta['source_updated_at'] = source_updated_at

                rag_system.add_chunk(
                    knowledge_base_id=kb_id,
                    content=content,
                    source_type=file_type or 'unknown',
                    source_path=source_path,
                    metadata=base_meta,
                )
                added += 1
            
            total_chunks = added
            # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫
            log = KnowledgeImportLog(
                knowledge_base_id=kb_id,
                user_telegram_id=tg_id,
                username=username,
                action_type="document",
                source_path=document_info['file_name'] or '',
                total_chunks=added,
            )
            session.add(log)
            session.commit()
            emit_n8n_import_event(
                kb_id=kb_id,
                action_type="document",
                source_path=document_info['file_name'] or '',
                total_chunks=added,
                user_info=user_info,
                extra={
                    "doc_hash": doc_hash,
                    "doc_version": doc_version,
                    "source_updated_at": source_updated_at,
                },
            )

        response_text = f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {added} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π!"
        
        if is_update:
            await message.reply_text(response_text, reply_markup=admin_menu())
        else:
            await query_or_update.edit_message_text(response_text, reply_markup=admin_menu())
    except Exception as e:
        error_text = f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}"
        if is_update:
            await message.reply_text(error_text)
        else:
            try:
                await query_or_update.edit_message_text(error_text)
            except:
                pass
    finally:
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    user = await check_user(update)
    if not user or user.role != 'admin':
        await update.message.reply_text("–¢–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã.")
        return
    
    document = update.message.document
    if not document:
        return
    
    file_name = document.file_name or ''
    file_type = file_name.split('.')[-1].lower() if '.' in file_name else None
    state = context.user_data.get('state')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–∂–∏–¥–∞–µ—Ç—Å—è –ª–∏ ZIP –∞—Ä—Ö–∏–≤ –¥–ª—è –≤–∏–∫–∏
    if state == 'waiting_wiki_zip' and file_type == 'zip':
        kb_id = context.user_data.get('wiki_zip_kb_id')
        wiki_url = context.user_data.get('wiki_zip_url')
        
        if not kb_id or not wiki_url:
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏–ª–∏ URL –≤–∏–∫–∏.")
            context.user_data.pop('state', None)
            context.user_data.pop('wiki_zip_kb_id', None)
            context.user_data.pop('wiki_zip_url', None)
            return
        
        await update.message.reply_text("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ ZIP –∞—Ä—Ö–∏–≤–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤–∏–∫–∏...\n\n–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è.")
        
        try:
            # –°–∫–∞—á–∞—Ç—å ZIP —Ñ–∞–π–ª
            bot = update.get_bot()
            file = await bot.get_file(document.file_id)
            import tempfile
            temp_zip_path = os.path.join(tempfile.gettempdir(), f"wiki_zip_{document.file_id}.zip")
            await file.download_to_drive(temp_zip_path)
            
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–∫–∏ –∏–∑ ZIP
            from wiki_git_loader import load_wiki_from_zip_async
            stats = await load_wiki_from_zip_async(temp_zip_path, wiki_url, kb_id)
            
            # –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.unlink(temp_zip_path)
            except Exception:
                pass
            
            deleted = stats.get("deleted_chunks", 0)
            files = stats.get("files_processed", 0)
            added = stats.get("chunks_added", 0)
            wiki_root = stats.get("wiki_root", wiki_url)
            processed_files = stats.get("processed_files", [])
            
            # –û–±–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å RAG —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–æ–≤—ã–º —á–∞–Ω–∫–∞–º
            try:
                rag_system.index = None
                rag_system.chunks = []
                logger.info("[wiki-zip] –ò–Ω–¥–µ–∫—Å RAG —Å–∏—Å—Ç–µ–º—ã —Å–±—Ä–æ—à–µ–Ω, –±—É–¥–µ—Ç –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –ø–æ–∏—Å–∫–µ")
            except Exception as idx_error:
                logger.warning(f"[wiki-zip] –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å: {idx_error}")
            
            # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
            from database import KnowledgeImportLog, User
            tg_id = str(update.effective_user.id) if update.effective_user else ""
            db_user = session.query(User).filter_by(telegram_id=tg_id).first() if tg_id else None
            username = db_user.username if db_user else tg_id
            user_info = {"telegram_id": tg_id, "username": username}
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ –≤ –∂—É—Ä–Ω–∞–ª
            for file_info in processed_files:
                log = KnowledgeImportLog(
                    knowledge_base_id=kb_id,
                    user_telegram_id=tg_id,
                    username=username,
                    action_type="archive",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º "archive" –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    source_path=file_info['wiki_url'],  # URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤–∏–∫–∏
                    total_chunks=file_info['chunks'],
                )
                session.add(log)
            session.commit()
            
            try:
                from bot_handlers import emit_n8n_import_event
                emit_n8n_import_event(
                    kb_id=kb_id,
                    action_type="wiki_zip",
                    source_path=wiki_root,
                    total_chunks=added,
                    user_info=user_info,
                    extra={
                        "deleted_chunks": deleted,
                        "files_processed": files,
                        "wiki_root": wiki_root,
                        "original_url": wiki_url,
                    },
                )
            except ImportError:
                logger.warning("n8n integration not available")
            
            text = (
                "‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–∫–∏ –∏–∑ ZIP –∞—Ä—Ö–∏–≤–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n\n"
                f"–ò—Å—Ö–æ–¥–Ω—ã–π URL: {wiki_url}\n"
                f"–ö–æ—Ä–Ω–µ–≤–æ–π wiki-URL: {wiki_root}\n"
                f"–£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {deleted}\n"
                f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {files}\n"
                f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {added}"
            )
            from templates.buttons import kb_actions_menu
            await update.message.reply_text(text, reply_markup=kb_actions_menu(kb_id))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∏–∫–∏ –∏–∑ ZIP: {e}", exc_info=True)
            await update.message.reply_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤–∏–∫–∏ –∏–∑ ZIP: {str(e)}\n\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:\n"
                "‚Ä¢ ZIP –∞—Ä—Ö–∏–≤ —Å–æ–¥–µ—Ä–∂–∏—Ç markdown —Ñ–∞–π–ª—ã (.md)\n"
                "‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞—Ä—Ö–∏–≤–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –≤–∏–∫–∏\n"
                "‚Ä¢ URL –≤–∏–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π"
            )
        finally:
            # –û—á–∏—Å—Ç–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            context.user_data.pop('state', None)
            context.user_data.pop('wiki_zip_kb_id', None)
            context.user_data.pop('wiki_zip_url', None)
        return
    
    # –û–±—ã—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    kb_id = context.user_data.get('kb_id')
    
    logger.info("–ü–æ–ª—É—á–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: file_name=%s, file_type=%s, kb_id=%s", file_name, file_type, kb_id)
    
    # –ï—Å–ª–∏ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –≤—ã–±—Ä–∞–Ω–∞, –ø–æ–∫–∞–∑–∞—Ç—å –º–µ–Ω—é –≤—ã–±–æ—Ä–∞
    if not kb_id:
        kbs = rag_system.list_knowledge_bases()
        if not kbs:
            await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏.")
            return
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –∑–∞–≥—Ä—É–∑–∫–∏
        context.user_data['pending_document'] = {
            'file_id': document.file_id,
            'file_name': document.file_name,
            'file_type': file_type
        }
        await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞:", reply_markup=knowledge_base_menu(kbs))
        return
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–ø—Ä—è–º—É—é
    await load_document_to_kb(update, context, {
        'file_id': document.file_id,
        'file_name': document.file_name,
        'file_type': file_type
    }, kb_id)
    
    context.user_data['kb_id'] = None


async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    user = await check_user(update)
    if not user:
        return
    
    photo = update.message.photo[-1]  # –°–∞–º–æ–µ –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    temp_path = None
    
    try:
        file = await context.bot.get_file(photo.file_id)
        temp_path = os.path.join(tempfile.gettempdir(), f"{photo.file_id}.jpg")
        await file.download_to_drive(temp_path)
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ RAG
        kb_id = context.user_data.get('kb_id')
        
        # –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é)
        image_model = getattr(user, 'preferred_image_model', None) or (user.preferred_model if user.preferred_model else None)
        
        if kb_id:
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ: —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –±—ã–ª)
            source_path = f"photo_{photo.file_id}.jpg"
            rag_system.delete_chunks_by_source_exact(
                knowledge_base_id=kb_id,
                source_type='image',
                source_path=source_path,
            )

            # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ RAG
            processed_text = image_processor.process_image_for_rag(
                temp_path,
                model=image_model,
            )
            source_updated_at = datetime.now(timezone.utc).isoformat()

            rag_system.add_chunk(
                knowledge_base_id=kb_id,
                content=processed_text,
                source_type='image',
                source_path=source_path,
                metadata={
                    'type': 'image',
                    'file_id': photo.file_id,
                    'source_updated_at': source_updated_at,
                },
            )
            # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫
            tg_id = str(update.effective_user.id) if update.effective_user else ""
            db_user = session.query(User).filter_by(telegram_id=tg_id).first() if tg_id else None
            username = db_user.username if db_user else tg_id
            log = KnowledgeImportLog(
                knowledge_base_id=kb_id,
                user_telegram_id=tg_id,
                username=username,
                action_type="image",
                source_path=f"photo_{photo.file_id}.jpg",
                total_chunks=1,
            )
            session.add(log)
            session.commit()
            user_info = {"telegram_id": tg_id, "username": username}
            emit_n8n_import_event(
                kb_id=kb_id,
                action_type="image",
                source_path=f"photo_{photo.file_id}.jpg",
                total_chunks=1,
                user_info=user_info,
                extra={"file_id": photo.file_id},
            )
            await update.message.reply_text("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π!", reply_markup=admin_menu())
        else:
            # –ü—Ä–æ—Å—Ç–æ –æ–ø–∏—Å–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É—è –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            description = image_processor.describe_image(
                temp_path,
                "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ. –ë—É–¥—å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∏ —Ç–æ—á–Ω—ã–º.",
                model=image_model,
            )
            menu = main_menu(is_admin=(user.role == 'admin'))
            answer = format_text_safe(f"üñºÔ∏è –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n\n{description}")
            await update.message.reply_text(answer, reply_markup=menu, parse_mode=None)
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


async def load_web_page(update: Update, context: ContextTypes.DEFAULT_TYPE, url: str, kb_id: int):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    try:
        chunks = document_loader_manager.load_document(url, 'web')
        
        added = 0
        # –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏)
        rag_system.delete_chunks_by_source_exact(
            knowledge_base_id=kb_id,
            source_type='web',
            source_path=url,
        )

        # –í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–æ –∂—É—Ä–Ω–∞–ª—É –∑–∞–≥—Ä—É–∑–æ–∫)
        existing_logs = session.query(KnowledgeImportLog).filter_by(
            knowledge_base_id=kb_id,
            source_path=url,
        ).count()
        doc_version = existing_logs + 1
        source_updated_at = datetime.now(timezone.utc).isoformat()

        for chunk in chunks:
            content = chunk['content']
            base_meta = dict(chunk.get('metadata') or {})
            base_meta.setdefault('title', chunk.get('title') or url)
            base_meta['language'] = detect_language(content) if content else 'ru'
            base_meta['doc_version'] = doc_version
            base_meta['source_updated_at'] = source_updated_at

            rag_system.add_chunk(
                knowledge_base_id=kb_id,
                content=content,
                source_type='web',
                source_path=url,
                metadata=base_meta,
            )
            added += 1
        
        # –ó–∞–ø–∏—Å–∞—Ç—å –≤ –∂—É—Ä–Ω–∞–ª –∑–∞–≥—Ä—É–∑–æ–∫
        tg_id = str(update.effective_user.id) if update.effective_user else ""
        db_user = session.query(User).filter_by(telegram_id=tg_id).first() if tg_id else None
        username = db_user.username if db_user else tg_id
        user_info = {"telegram_id": tg_id, "username": username}
        log = KnowledgeImportLog(
            knowledge_base_id=kb_id,
            user_telegram_id=tg_id,
            username=username,
            action_type="web",
            source_path=url,
            total_chunks=added,
        )
        session.add(log)
        session.commit()
        emit_n8n_import_event(
            kb_id=kb_id,
            action_type="web",
            source_path=url,
            total_chunks=added,
            user_info=user_info,
            extra={
                "doc_version": doc_version,
                "source_updated_at": source_updated_at,
            },
        )

        await update.message.reply_text(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {added} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã!", reply_markup=admin_menu())
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã: {str(e)}")
