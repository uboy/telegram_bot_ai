"""
–¢–µ—Å—Ç—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Å—Ç-–Ω–∞–±–æ—Ä–∞ rag_eval.yaml
"""
import pytest

yaml = pytest.importorskip("yaml")
import re
from pathlib import Path
from typing import List, Dict, Any
import sys
import os

# –î–æ–±–∞–≤–∏—Ç—å –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from shared.rag_system import rag_system
from shared.database import Session, KnowledgeBase


def load_test_cases() -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç-–∫–µ–π—Å—ã –∏–∑ YAML —Ñ–∞–π–ª–∞"""
    TEST_YAML_FILE = "rag_eval.yaml"
    test_file = Path(__file__).parent / TEST_YAML_FILE
    with open(test_file, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)
    return data.get('test_cases', [])


def check_snippet_in_content(snippet: str, content: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ª–∏ snippet (regex) –≤ content"""
    try:
        pattern = re.compile(snippet, re.IGNORECASE | re.DOTALL)
        return bool(pattern.search(content))
    except re.error:
        # –ï—Å–ª–∏ –Ω–µ –≤–∞–ª–∏–¥–Ω—ã–π regex, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—É—é —Å—Ç—Ä–æ–∫—É
        return snippet.lower() in content.lower()


def evaluate_retrieval(test_case: Dict, results: List[Dict], kb_id: int) -> Dict[str, Any]:
    """–û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ retrieval –¥–ª—è —Ç–µ—Å—Ç-–∫–µ–π—Å–∞"""
    metrics = {
        'retrieval_at_k': 0,
        'found_expected_source': False,
        'found_snippets': [],
        'found_commands': [],
        'best_score': 0.0,
        'total_results': len(results)
    }
    
    expected_source = test_case.get('expected_source', '')
    expected_snippets = test_case.get('expected_snippets', [])
    expected_commands = test_case.get('expected_commands', [])
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º top-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    k = 5
    top_k_results = results[:k]
    
    for idx, result in enumerate(top_k_results):
        content = result.get('content', '')
        source_path = result.get('source_path', '')
        score = float(result.get('rerank_score', result.get('distance', 0.0)))
        
        if idx == 0:
            metrics['best_score'] = score
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        if expected_source and expected_source.lower() in source_path.lower():
            metrics['found_expected_source'] = True
            metrics['retrieval_at_k'] = idx + 1
            break
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ snippets
        for snippet in expected_snippets:
            if snippet not in metrics['found_snippets']:
                if check_snippet_in_content(snippet, content):
                    metrics['found_snippets'].append(snippet)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–∞–Ω–¥
        for cmd in expected_commands:
            if cmd not in metrics['found_commands']:
                if check_snippet_in_content(cmd, content):
                    metrics['found_commands'].append(cmd)
    
    return metrics


def evaluate_answer(answer: str, test_case: Dict) -> Dict[str, Any]:
    """–û—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞ LLM"""
    metrics = {
        'contains_commands': False,
        'contains_source': False,
        'contains_snippets': [],
        'answer_length': len(answer)
    }
    
    expected_snippets = test_case.get('expected_snippets', [])
    expected_commands = test_case.get('expected_commands', [])
    expected_source = test_case.get('expected_source', '')
    
    answer_lower = answer.lower()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–∞–Ω–¥
    for cmd in expected_commands:
        if check_snippet_in_content(cmd, answer):
            metrics['contains_commands'] = True
            break
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if expected_source and expected_source.lower() in answer_lower:
        metrics['contains_source'] = True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ snippets
    for snippet in expected_snippets:
        if check_snippet_in_content(snippet, answer):
            metrics['contains_snippets'].append(snippet)
    
    return metrics


def run_test_case(test_case: Dict, kb_id: int) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–¥–∏–Ω —Ç–µ—Å—Ç-–∫–µ–π—Å"""
    query = test_case['query']
    
    print(f"\n{'='*80}")
    print(f"–¢–µ—Å—Ç: {test_case.get('id', 'unknown')}")
    print(f"–ó–∞–ø—Ä–æ—Å: {query}")
    print(f"–û–∂–∏–¥–∞–µ–º—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫: {test_case.get('expected_source', 'N/A')}")
    print(f"{'='*80}")
    
    # –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫
    results = rag_system.search(
        query=query,
        knowledge_base_id=kb_id,
        top_k=10
    )
    
    # –û—Ü–µ–Ω–∏—Ç—å retrieval
    retrieval_metrics = evaluate_retrieval(test_case, results, kb_id)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (—Å–∏–º—É–ª—è—Ü–∏—è —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç LLM)
    # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è –≤ backend_service/api/routes/rag.py
    answer_parts = []
    if results:
        best_result = results[0]
        answer_parts.append(f"Found information:\n{best_result.get('content', '')[:500]}")
        answer_parts.append(f"\nSource: {best_result.get('source_path', 'N/A')}")
    
    answer = "\n".join(answer_parts)
    answer_metrics = evaluate_answer(answer, test_case)
    
    # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
    return {
        'test_id': test_case.get('id'),
        'query': query,
        'retrieval': retrieval_metrics,
        'answer': answer_metrics,
        'results_count': len(results),
        'passed': (
            retrieval_metrics['found_expected_source'] or 
            len(retrieval_metrics['found_snippets']) >= len(test_case.get('expected_snippets', [])) * 0.5
        )
    }


def run_all_tests(kb_name: str = "Test KB") -> Dict[str, Any]:
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã"""
    session = Session()
    
    # –ù–∞–π—Ç–∏ –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
    kb = session.query(KnowledgeBase).filter_by(name=kb_name).first()
    if not kb:
        print(f"‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π '{kb_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        print("–°–æ–∑–¥–∞–π—Ç–µ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ Sync&Build.md –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —Ç–µ—Å—Ç–æ–≤.")
        return {'error': f"Knowledge base '{kb_name}' not found"}
    
    kb_id = kb.id
    print(f"üìö –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: {kb_name} (ID: {kb_id})")
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç-–∫–µ–π—Å—ã
    test_cases = load_test_cases()
    print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–µ—Å—Ç-–∫–µ–π—Å–æ–≤: {len(test_cases)}")
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç—ã
    results = []
    for test_case in test_cases:
        result = run_test_case(test_case, kb_id)
        results.append(result)
        
        # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ {result['test_id']}:")
        print(f"   Retrieval@5: {'‚úÖ' if result['retrieval']['retrieval_at_k'] > 0 else '‚ùå'}")
        print(f"   –ù–∞–π–¥–µ–Ω–Ω—ã—Ö snippets: {len(result['retrieval']['found_snippets'])}/{len(test_case.get('expected_snippets', []))}")
        print(f"   –ù–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–º–∞–Ω–¥: {len(result['retrieval']['found_commands'])}/{len(test_case.get('expected_commands', []))}")
        print(f"   Best score: {result['retrieval']['best_score']:.4f}")
        print(f"   –°—Ç–∞—Ç—É—Å: {'‚úÖ PASSED' if result['passed'] else '‚ùå FAILED'}")
    
    # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    passed = sum(1 for r in results if r['passed'])
    total = len(results)
    accuracy = (passed / total * 100) if total > 0 else 0
    
    summary = {
        'total_tests': total,
        'passed': passed,
        'failed': total - passed,
        'accuracy': accuracy,
        'results': results
    }
    
    print(f"\n{'='*80}")
    print(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print(f"{'='*80}")
    print(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total}")
    print(f"–ü—Ä–æ–π–¥–µ–Ω–æ: {passed}")
    print(f"–ü—Ä–æ–≤–∞–ª–µ–Ω–æ: {total - passed}")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1f}%")
    print(f"{'='*80}")
    
    session.close()
    return summary


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã")
    parser.add_argument("--kb-name", default="Test KB", help="–ò–º—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    parser.add_argument("--kb-id", type=int, help="ID –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ --kb-name)")
    
    args = parser.parse_args()
    
    if args.kb_id:
        session = Session()
        kb = session.query(KnowledgeBase).filter_by(id=args.kb_id).first()
        if not kb:
            print(f"‚ùå –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å ID {args.kb_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            sys.exit(1)
        kb_name = kb.name
        session.close()
    else:
        kb_name = args.kb_name
    
    run_all_tests(kb_name)

